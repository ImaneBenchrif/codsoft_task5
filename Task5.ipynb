{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f095862d",
   "metadata": {},
   "source": [
    "# 1. Import Libraries and Define Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00303d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from collections import Counter\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = \"C:/Users/DELL/Downloads/TASKS/TASK1/DATA\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c463b51",
   "metadata": {},
   "source": [
    "# 2. Function to Load Images from Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ded7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from directory\n",
    "def load_images_from_dir(dir_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(dir_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85affcc8",
   "metadata": {},
   "source": [
    "# 3. Function to Load All Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68f82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load all images\n",
    "def load_all_images(data_dir):\n",
    "    actor_dirs = [\"Elon_Musk\", \"Angelina_Jolie\", \"Stromae\"]\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for actor in actor_dirs:\n",
    "        dir_path = os.path.join(data_dir, actor)\n",
    "        imgs, lbls = load_images_from_dir(dir_path, actor)\n",
    "        images.extend(imgs)\n",
    "        labels.extend(lbls)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f29b8d",
   "metadata": {},
   "source": [
    "# 4. Initialize FaceNet and Get Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714d0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FaceNet\n",
    "embedder = FaceNet()\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(face_img, embedder):\n",
    "    face_img = face_img.astype('float32')\n",
    "    face_img = np.expand_dims(face_img, axis=0)\n",
    "    yhat = embedder.embeddings(face_img)\n",
    "    return yhat[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3e8f1",
   "metadata": {},
   "source": [
    "# 5. Load Data and Compute Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c400cf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_22256/723465572.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(images), np.array(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load all images\n",
    "X, Y = load_all_images(DATA_DIR)\n",
    "\n",
    "# Calculate embeddings\n",
    "EMBEDDED_X = [get_embedding(img, embedder) for img in X]\n",
    "EMBEDDED_X = np.asarray(EMBEDDED_X)\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "Y_encoded = encoder.fit_transform(Y)\n",
    "\n",
    "# Flatten data\n",
    "EMBEDDED_X_flat = EMBEDDED_X.reshape(EMBEDDED_X.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c4000",
   "metadata": {},
   "source": [
    "# 6. Define Parameter Grid for GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f310e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'svc1__C': [0.1, 0.5, 1.0],\n",
    "    'svc2__C': [0.1, 0.5, 1.0],\n",
    "    'svc2__gamma': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize models with different parameters\n",
    "model1 = SVC(kernel='linear', probability=True)\n",
    "model2 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[('svc1', model1), ('svc2', model2)], voting='soft')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=ensemble_model, param_grid=param_grid, cv=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703d081",
   "metadata": {},
   "source": [
    "# 7. Stratified K-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01569419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold Cross Validation with more folds\n",
    "kf = StratifiedKFold(n_splits=7)  # Increase the number of splits if needed\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "def check_distribution(labels, title):\n",
    "    class_distribution = Counter(labels)\n",
    "    print(f\"Distribution des classes dans {title}:\")\n",
    "    for label, count in class_distribution.items():\n",
    "        print(f\"{label}: {count}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Loop through folds\n",
    "for train_index, val_test_index in kf.split(EMBEDDED_X_flat, Y_encoded):\n",
    "    X_train, X_temp = EMBEDDED_X_flat[train_index], EMBEDDED_X_flat[val_test_index]\n",
    "    y_train, y_temp = Y_encoded[train_index], Y_encoded[val_test_index]\n",
    "   \n",
    "    # Further split temp set into validation and test sets with increased size\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.55, random_state=75)  # Increase test size\n",
    "    for val_index, test_index in sss.split(X_temp, y_temp):\n",
    "        X_val, X_test = X_temp[val_index], X_temp[test_index]\n",
    "        y_val, y_test = y_temp[val_index], y_temp[test_index]\n",
    "\n",
    "    \n",
    "    # Train model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate performance\n",
    "    ypreds_train = grid_search.best_estimator_.predict(X_train)\n",
    "    ypreds_val = grid_search.best_estimator_.predict(X_val)\n",
    "    ypreds_test = grid_search.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44baeffc",
   "metadata": {},
   "source": [
    "# 8. Real-Time Face Detection and Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "HAARCASCADE_PATH = \"C:/Users/DELL/Downloads/TASKS/TASK1/haarcascade_frontalface_default.xml\"\n",
    "SIMILARITY_THRESHOLD = 0.6\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "haarcascade = cv.CascadeClassifier(HAARCASCADE_PATH)\n",
    "facenet = FaceNet()\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    rgb_img = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    gray_img = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = haarcascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = rgb_img[y:y + h, x:x + w]\n",
    "        face = cv.resize(face, (160, 160))\n",
    "        img = np.expand_dims(face, axis=0)\n",
    "\n",
    "        # Get embeddings for the face\n",
    "        ypred = facenet.embeddings(img)\n",
    "\n",
    "        # Calculate similarity with known faces\n",
    "        similarities = cosine_similarity(ypred, EMBEDDED_X)\n",
    "        max_similarity = np.max(similarities)\n",
    "\n",
    "        # Determine label based on similarity\n",
    "        if max_similarity < SIMILARITY_THRESHOLD:\n",
    "            final_name = 'unknown'\n",
    "        else:\n",
    "            best_match_index = np.argmax(similarities)\n",
    "            final_name = Y[best_match_index]\n",
    "\n",
    "        # Draw rectangle and label on the face\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv.putText(frame, str(final_name), (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release capture and destroy all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
